# -*- coding: utf-8 -*-
"""
è‡ªå®šä¹‰æ•°æ®é›†è®­ç»ƒè„šæœ¬
ä½¿ç”¨æŒ‡å®šè·¯å¾„çš„æ•°æ®é›†è®­ç»ƒ EfficientNet-B0 æ¨¡å‹
"""
from torchvision import transforms
from torchvision.models import EfficientNet_B0_Weights
import os
import math
import random
import time
import argparse
from pathlib import Path
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split, Subset
from torchvision import transforms
from torchvision.datasets import ImageFolder
from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import numpy as np
import urllib.error

# ----------------------------
# è¶…å‚æ•°
# ----------------------------
DATASET_DIR = r"C:\Users\33106\Desktop\æ¯ä¸ªç±»åˆ«æä¾›5å¼ çš„éƒ¨åˆ†æ•°æ®é›†\æ¯ä¸ªç±»åˆ«æä¾›5å¼ çš„éƒ¨åˆ†æ•°æ®é›†"

BATCH_SIZE   = 16
EPOCHS       = 50
LR           = 2e-4
WEIGHT_DECAY = 1e-4
EARLY_STOP   = 8        # è¿ç»­å¤šå°‘è½® val å‡†ç¡®ç‡ä¸æå‡åˆ™æ—©åœ
IMG_SIZE     = 224
NUM_WORKERS  = 0        # Windows å»ºè®® 0ï¼›Linux å¯è®¾ 4/8
SEED         = 42

# è‹¥ä½ æœ‰æœ¬åœ°çš„ EfficientNet-B0 æƒé‡ï¼ˆstate_dictï¼‰ï¼Œå¯å¡«å…¥è·¯å¾„ï¼›å¦åˆ™ä¿æŒ None
LOCAL_WEIGHTS_PATH = None  # ä¾‹å¦‚ r"C:\Users\33106\Desktop\shipin\efficientnet_b0.pth"

# ----------------------------
# éšæœºç§å­
# ----------------------------
def set_seed(seed=SEED):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)

# ----------------------------
# æ¨¡å‹æ„å»ºï¼ˆè‡ªåŠ¨å›é€€ï¼‰
# ----------------------------
def build_model(num_classes, try_pretrained=True, local_weights_path=None):
    """
    - local_weights_path ä¼˜å…ˆï¼šå®Œå…¨ç¦»çº¿ï¼Œç”¨ä½ è‡ªå·±çš„ .pth
    - try_pretrained=Trueï¼šå°è¯•ä» torchvision åŠ è½½ ImageNet é¢„è®­ç»ƒï¼ˆè”ç½‘ï¼‰ï¼Œå¤±è´¥åˆ™è‡ªåŠ¨å›é€€åˆ°éšæœºåˆå§‹åŒ–
    """
    if local_weights_path is not None:
        print(f"ğŸŸ¡ ä½¿ç”¨æœ¬åœ°æƒé‡ï¼š{local_weights_path}")
        model = efficientnet_b0(weights=None)
        state = torch.load(local_weights_path, map_location="cpu")
        model.load_state_dict(state, strict=False)
        print("âœ… å·²åŠ è½½æœ¬åœ°æƒé‡ .pth")
    elif try_pretrained:
        try:
            weights = EfficientNet_B0_Weights.IMAGENET1K_V1
            model = efficientnet_b0(weights=weights)
            print("âœ… å·²åŠ è½½ ImageNet é¢„è®­ç»ƒæƒé‡")
        except (urllib.error.URLError, RuntimeError, OSError) as e:
            print(f"âš ï¸ é¢„è®­ç»ƒæƒé‡ä¸‹è½½å¤±è´¥ï¼Œæ”¹ä¸ºéšæœºåˆå§‹åŒ–ï¼š{e}")
            model = efficientnet_b0(weights=None)
    else:
        model = efficientnet_b0(weights=None)
    
    # æ›¿æ¢åˆ†ç±»å¤´
    in_features = model.classifier[1].in_features
    model.classifier[1] = nn.Linear(in_features, num_classes)
    return model

# ----------------------------
# æ•°æ®å¢å¼º & å½’ä¸€åŒ–
# ----------------------------
def build_transforms(img_size: int = 224):
    """
    é€šç”¨ä¸”å…¼å®¹å„ç‰ˆæœ¬ torchvision çš„é¢„å¤„ç†ã€‚
    è¯„ä¼°/æµ‹è¯•ç›´æ¥ç”¨å®˜æ–¹æƒé‡çš„ transformsï¼›
    è®­ç»ƒåœ¨åŒæ ·çš„ mean/std ä¸ŠåŠ è½»é‡æ•°æ®å¢å¼ºã€‚
    """
    base = EfficientNet_B0_Weights.IMAGENET1K_V1
    mean = base.meta.get("mean", [0.485, 0.456, 0.406])
    std  = base.meta.get("std",  [0.229, 0.224, 0.225])

    # è¯„ä¼°/æµ‹è¯•ï¼šå®˜æ–¹é¢„å¤„ç†ç®¡çº¿ï¼ˆå·²å« Resize/CenterCrop/ToTensor/Normalizeï¼‰
    eval_tfms = base.transforms()

    # è®­ç»ƒï¼šåœ¨ç›¸åŒå‡ ä½•å°ºåº¦ä¸Šå¢åŠ è½»é‡å¢å¼ºï¼Œå†æ‰‹åŠ¨ Normalize
    train_tfms = transforms.Compose([
        transforms.Resize(int(img_size * 1.15)),
        transforms.CenterCrop(img_size),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomRotation(10),
        transforms.ColorJitter(0.2, 0.2, 0.2, 0.05),
        transforms.ToTensor(),
        transforms.Normalize(mean=mean, std=std),
    ])

    return train_tfms, eval_tfms

# ----------------------------
# æ•°æ®é›†å‡†å¤‡
# æ”¯æŒä¸¤ç§ç›®å½•ç»“æ„ï¼š
# 1) æ ¹ç›®å½•ä¸‹å·²æœ‰ train/val/test å­æ–‡ä»¶å¤¹
# 2) æ ¹ç›®å½•ä¸ºç±»åˆ«æ–‡ä»¶å¤¹é›†åˆï¼ˆåˆ™è‡ªåŠ¨ 8:1:1 åˆ’åˆ†ï¼‰
# ----------------------------
def prepare_dataloaders(root_dir, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS):
    root = Path(root_dir)
    assert root.exists(), f"æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨ï¼š{root}"

    train_tfms, eval_tfms = build_transforms()

    subdirs = [p.name.lower() for p in root.iterdir() if p.is_dir()]

    has_split = all(d in subdirs for d in ["train", "val", "test"])

    if has_split:
        train_ds = ImageFolder(root / "train", transform=train_tfms)
        val_ds   = ImageFolder(root / "val",   transform=eval_tfms)
        test_ds  = ImageFolder(root / "test",  transform=eval_tfms)
        classes  = train_ds.classes
        print("âœ… ä½¿ç”¨ç°æœ‰çš„ train/val/test ç›®å½•")
    else:
        # è‡ªåŠ¨åˆ’åˆ† 8:1:1
        full_ds = ImageFolder(root, transform=train_tfms)
        classes = full_ds.classes

        n = len(full_ds)
        n_train = int(n * 0.8)
        n_val   = int(n * 0.1)
        n_test  = n - n_train - n_val

        # ä¸ºäº† val/test ä¸ç”¨è®­ç»ƒå¢å¼ºï¼Œåšä¸¤ä¸ª"è§†å›¾åŒ…è£…"
        idxs = list(range(n))
        random.shuffle(idxs)
        train_idx = idxs[:n_train]
        val_idx   = idxs[n_train:n_train+n_val]
        test_idx  = idxs[n_train+n_val:]

        train_ds = Subset(ImageFolder(root, transform=train_tfms), train_idx)

        # åŒ…ä¸€å±‚ä»¥æ”¹ val/test çš„ transform
        val_base  = ImageFolder(root, transform=eval_tfms)
        test_base = ImageFolder(root, transform=eval_tfms)
        val_ds  = Subset(val_base,  val_idx)
        test_ds = Subset(test_base, test_idx)

        # ç»™ Subset è¡¥ classes å±æ€§ï¼ˆä¾¿äºåç»­ä½¿ç”¨ï¼‰
        train_ds.classes = classes
        val_ds.classes = classes
        test_ds.classes = classes

        print(f"âœ… è‡ªåŠ¨åˆ’åˆ†æ•°æ®é›†ï¼štrain {n_train} / val {n_val} / test {n_test}")

    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,
                              num_workers=num_workers, pin_memory=True)
    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False,
                              num_workers=num_workers, pin_memory=True)
    test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False,
                              num_workers=num_workers, pin_memory=True)

    return train_loader, val_loader, test_loader, classes

# ----------------------------
# è®­ç»ƒä¸éªŒè¯
# ----------------------------
def train_one_epoch(model, loader, criterion, optimizer, device, scaler=None):
    model.train()
    loss_sum, correct, total = 0.0, 0, 0

    for imgs, labels in loader:
        imgs, labels = imgs.to(device), labels.to(device)
        optimizer.zero_grad(set_to_none=True)

        if scaler is not None:
            with torch.cuda.amp.autocast():
                outputs = model(imgs)
                loss = criterion(outputs, labels)
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
        else:
            outputs = model(imgs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

        loss_sum += loss.item() * imgs.size(0)
        preds = outputs.argmax(dim=1)
        correct += (preds == labels).sum().item()
        total   += imgs.size(0)

    return loss_sum/total, correct/total

@torch.no_grad()
def evaluate(model, loader, criterion, device):
    model.eval()
    loss_sum, correct, total = 0.0, 0, 0
    all_preds, all_labels = [], []

    for imgs, labels in loader:
        imgs, labels = imgs.to(device), labels.to(device)
        outputs = model(imgs)
        loss = criterion(outputs, labels)

        loss_sum += loss.item() * imgs.size(0)
        preds = outputs.argmax(dim=1)
        correct += (preds == labels).sum().item()
        total   += imgs.size(0)

        all_preds.append(preds.cpu())
        all_labels.append(labels.cpu())

    avg_loss = loss_sum/total
    acc = correct/total
    all_preds  = torch.cat(all_preds).numpy()
    all_labels = torch.cat(all_labels).numpy()

    return avg_loss, acc, all_preds, all_labels

# ----------------------------
# ä¸»æµç¨‹
# ----------------------------
def main():
    set_seed(SEED)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    torch.backends.cudnn.benchmark = True
    print(f"ğŸš€ Device: {device}")

    # æ£€æŸ¥æ•°æ®é›†è·¯å¾„
    if not os.path.exists(DATASET_DIR):
        print(f"âŒ æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨ï¼š{DATASET_DIR}")
        print("è¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®")
        return

    train_loader, val_loader, test_loader, classes = prepare_dataloaders(DATASET_DIR, BATCH_SIZE, NUM_WORKERS)

    num_classes = len(classes)
    print(f"ğŸ”¤ ç±»åˆ«æ•°ï¼š{num_classes}")
    print(f"ğŸ“‹ ç±»åˆ«åˆ—è¡¨ï¼š{classes}")

    model = build_model(
        num_classes,
        try_pretrained=True,
        local_weights_path=LOCAL_WEIGHTS_PATH
    ).to(device)

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)

    use_amp = (device.type == "cuda")
    scaler = torch.cuda.amp.GradScaler() if use_amp else None

    best_val_acc = 0.0
    best_path = "best_model_custom.pth"
    no_improve = 0

    print("==== å¼€å§‹è®­ç»ƒ ====")
    for epoch in range(1, EPOCHS+1):
        t0 = time.time()
        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device, scaler)
        val_loss, val_acc, _, _ = evaluate(model, val_loader, criterion, device)
        scheduler.step()

        dt = time.time() - t0
        print(f"[{epoch:03d}/{EPOCHS}] "
              f"train_loss={train_loss:.4f} acc={train_acc:.4f} | "
              f"val_loss={val_loss:.4f} acc={val_acc:.4f} | "
              f"lr={scheduler.get_last_lr()[0]:.6f} | {dt:.1f}s")

        # ä¿å­˜æœ€ä½³
        if val_acc > best_val_acc + 1e-6:
            best_val_acc = val_acc
            torch.save({
                "state_dict": model.state_dict(),
                "classes": classes,
                "val_acc": val_acc,
                "num_classes": num_classes,
            }, best_path)
            print(f"  âœ… New best! ä¿å­˜æ¨¡å‹åˆ° {best_path}  (val_acc={val_acc:.4f})")
            no_improve = 0
        else:
            no_improve += 1
            if no_improve >= EARLY_STOP:
                print(f"â¹ï¸ æ—©åœï¼šè¿ç»­ {EARLY_STOP} è½®æœªæå‡")
                break

    # åŠ è½½æœ€ä½³å¹¶åœ¨ test ä¸Šè¯„ä¼°
    if os.path.exists(best_path):
        ckpt = torch.load(best_path, map_location=device)
        model.load_state_dict(ckpt["state_dict"])
        print(f"ğŸ“¦ å·²åŠ è½½æœ€ä½³æ¨¡å‹ï¼ˆval_acc={ckpt.get('val_acc',0):.4f}ï¼‰è¿›è¡Œæµ‹è¯•è¯„ä¼°")
    else:
        print("âš ï¸ æœªæ‰¾åˆ°æœ€ä½³æ¨¡å‹æ–‡ä»¶ï¼Œä½¿ç”¨å½“å‰æƒé‡è¿›è¡Œæµ‹è¯•è¯„ä¼°")

    test_loss, test_acc, test_preds, test_labels = evaluate(model, test_loader, criterion, device)
    print("\n==== æµ‹è¯•é›†è¡¨ç° ====")
    print(f"Test  Loss: {test_loss:.4f}")
    print(f"Test  Acc : {test_acc*100:.2f}%")  # <- ç»ˆç«¯è¾“å‡ºè¯†åˆ«å‡†ç¡®ç‡

    try:
        print("\nåˆ†ç±»æŠ¥å‘Šï¼š")
        print(classification_report(test_labels, test_preds, target_names=classes, digits=4))
    except Exception as e:
        print(f"åˆ†ç±»æŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼š{e}")

    try:
        cm = confusion_matrix(test_labels, test_preds)
        print("\næ··æ·†çŸ©é˜µï¼ˆè¡Œ=çœŸå®/åˆ—=é¢„æµ‹ï¼‰ï¼š")
        print(cm)
    except Exception as e:
        print(f"æ··æ·†çŸ©é˜µç”Ÿæˆå¤±è´¥ï¼š{e}")

    # ä¿å­˜ç±»åˆ«æ˜ å°„åˆ° label_map.jsonï¼ˆä¾›ç³»ç»Ÿä½¿ç”¨ï¼‰
    import json
    label_map_path = "server/assets/label_map.json"
    os.makedirs(os.path.dirname(label_map_path), exist_ok=True)
    with open(label_map_path, 'w', encoding='utf-8') as f:
        json.dump(classes, f, ensure_ascii=False, indent=2)
    print(f"\nâœ… å·²ä¿å­˜ç±»åˆ«æ˜ å°„åˆ° {label_map_path}")

    print("\nâœ… è®­ç»ƒå·²å®Œæˆã€‚")
    print(f"ğŸ“ æ¨¡å‹æ–‡ä»¶ï¼š{best_path}")
    print(f"ğŸ“‹ ç±»åˆ«æ˜ å°„ï¼š{label_map_path}")

if __name__ == "__main__":
    # å¯é€‰ï¼šå‘½ä»¤è¡Œå‚æ•°è¦†ç›–ï¼ˆä¸æƒ³ç”¨å¯å¿½ç•¥ï¼‰
    parser = argparse.ArgumentParser()
    parser.add_argument("--data", type=str, default=DATASET_DIR, help="æ•°æ®é›†æ ¹ç›®å½•")
    parser.add_argument("--epochs", type=int, default=EPOCHS)
    parser.add_argument("--batch", type=int, default=BATCH_SIZE)
    parser.add_argument("--lr", type=float, default=LR)
    parser.add_argument("--workers", type=int, default=NUM_WORKERS)
    parser.add_argument("--imgsz", type=int, default=IMG_SIZE)
    parser.add_argument("--local_weights", type=str, default=LOCAL_WEIGHTS_PATH)
    args = parser.parse_args()

    # è¦†ç›–å…¨å±€
    DATASET_DIR = args.data
    EPOCHS = args.epochs
    BATCH_SIZE = args.batch
    LR = args.lr
    NUM_WORKERS = args.workers
    IMG_SIZE = args.imgsz
    LOCAL_WEIGHTS_PATH = args.local_weights if args.local_weights not in [None, "None", ""] else None

    main()

